{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import predicate\n",
    "from route_optimization_ny import route_optimisation\n",
    "from predicate import use_predicate_logic\n",
    "from importlib import reload\n",
    "reload(predicate)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Note: Give location in format - Location, New York\") # We can do more locations but very far apart distance might not load in the map\n",
    "start_location=input(\"Start Location: \")\n",
    "end_location=input(\"End Location: \")\n",
    "\n",
    "route_optimisation(start_location,end_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base path to the dataset folder\n",
    "base_path = '/Users/riyanshibohra/Desktop/Datasets' # Replace with your path\n",
    "\n",
    "# Lists to store image paths\n",
    "list_other = []\n",
    "list_safe = []\n",
    "list_talking = []\n",
    "list_text = []\n",
    "list_turn = []\n",
    "\n",
    "# Paths for each category\n",
    "categories = {\n",
    "    'other_activities': list_other,\n",
    "    'safe_driving': list_safe,\n",
    "    'talking_phone': list_talking,\n",
    "    'texting_phone': list_text,\n",
    "    'turning': list_turn\n",
    "}\n",
    "\n",
    "# Loop through each category directory and append image paths\n",
    "for category, image_list in categories.items():\n",
    "    category_path = os.path.join(base_path, category)\n",
    "    for image in os.listdir(category_path):\n",
    "        if image.endswith(('.png', '.jpg')):\n",
    "            full_path = os.path.join(category_path, image)\n",
    "            image_list.append(full_path)\n",
    "            print(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the number of images in each category\n",
    "for category, image_list in categories.items():\n",
    "    print(f\"{category} has {len(image_list)} images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Visualization for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display images for a given category\n",
    "def display_images(images, title):\n",
    "    plt.figure(figsize=(10, 10))  \n",
    "    plt.suptitle(title)  \n",
    "\n",
    "    # Display up to 4 images\n",
    "    for i in range(min(4, len(images))):\n",
    "        img = Image.open(images[i])\n",
    "        plt.subplot(2, 2, i + 1)  # Arrange plots in 2x2 grid\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()  # Show the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display images from each category with custom titles\n",
    "for category, images in categories.items():\n",
    "    title = f\"{category.replace('_', ' ').title()} - Example Images\"\n",
    "    display_images(images, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine into a single list of image paths and labels\n",
    "image_paths = list_other + list_safe + list_talking + list_text + list_turn\n",
    "labels = [1] * len(list_other) + [0] * len(list_safe) + [4] * len(list_talking) + [3] * len(list_text) + [2] * len(list_turn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# First split to separate out the test set\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    image_paths, labels, test_size=0.15, random_state=42, stratify=labels)\n",
    "\n",
    "# Second split to separate out the validation set from the remaining training set\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.1765, random_state=42, stratify=y_train_val)  # 0.1765 â‰ˆ 15/85\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_distribution(labels, title):\n",
    "    from collections import Counter\n",
    "    distribution = Counter(labels)\n",
    "    total = sum(distribution.values())\n",
    "    for k in sorted(distribution):\n",
    "        print(f\"Class {k}: {distribution[k]/total:.2%}\")\n",
    "    print(f\"Total samples in {title}: {total}\")\n",
    "\n",
    "check_distribution(y_train, \"Training Set\")\n",
    "check_distribution(y_val, \"Validation Set\")\n",
    "check_distribution(y_test, \"Test Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes from the splits\n",
    "train_df = pd.DataFrame({'Image_Path': X_train, 'Label': y_train})\n",
    "val_df = pd.DataFrame({'Image_Path': X_val, 'Label': y_val})\n",
    "test_df = pd.DataFrame({'Image_Path': X_test, 'Label': y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_label_distribution(df, dataset_name):\n",
    "    print(f\"Label Distribution in {dataset_name}:\")\n",
    "    print(df['Label'].value_counts(normalize=True))  # This prints the percentage of each label\n",
    "\n",
    "print_label_distribution(train_df, \"Training Data\")\n",
    "print_label_distribution(val_df, \"Validation Data\")\n",
    "print_label_distribution(test_df, \"Test Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample_images(df, num_images=4):\n",
    "    sample = df.sample(n=num_images)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for index, row in enumerate(sample.itertuples(), 1):\n",
    "        img = Image.open(row.Image_Path)\n",
    "        plt.subplot(2, 2, index)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Class: {row.Label}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_sample_images(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle DataFrames\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "val_df = val_df.sample(frac=1).reset_index(drop=True)\n",
    "test_df = test_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Hyperparameters (Batch_Size, Height and Width)\n",
    "\n",
    "Batch_size = 64\n",
    "Img_height = 240\n",
    "Img_width = 240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescaling the images to put all images in same shape for input layer of the model\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255.)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255.)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert integer labels in the dataframe to strings\n",
    "\n",
    "train_df['Label'] = train_df['Label'].astype(str)\n",
    "val_df['Label'] = val_df['Label'].astype(str)\n",
    "test_df['Label'] = test_df['Label'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Image_Path',  \n",
    "    y_col='Label',       \n",
    "    target_size=(Img_height, Img_width),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=Batch_size,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "valDataset = test_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col='Image_Path',\n",
    "    y_col='Label',\n",
    "    target_size=(Img_height, Img_width),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=Batch_size,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "testDataset = val_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='Image_Path',\n",
    "    y_col='Label',\n",
    "    target_size=(Img_height, Img_width),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=Batch_size,\n",
    "    shuffle=False,  # Generally, shuffling is not required for testing.\n",
    "    seed=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transfer_learning_model(input_shape=(240, 240, 3), num_classes=5):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    base_model.trainable = False  # Freeze the base model\n",
    "    \n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')  # Output layer\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and compile the model\n",
    "model = create_transfer_learning_model()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(trainDataset,\n",
    "                    epochs=20,  # You can adjust this based on the training progress\n",
    "                    validation_data=valDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'model' is your trained model (Create directory for your pc)\n",
    "model.save('/Users/riyanshibohra/Desktop/AI Project/my_model.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = load_model('/Users/riyanshibohra/Desktop/AI Project/my_model.h5') #Replace with the actual path to your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making Predictions on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a test dataset called 'testDataset'\n",
    "predictions = model.predict(testDataset)\n",
    "predicted_classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'testDataset' is a tf.data.Dataset or a generator that yields (input, label) pairs\n",
    "loss, accuracy = model.evaluate(testDataset)\n",
    "print(f\"Accuracy on the test set: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "training_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = range(1, len(training_loss) + 1)  # Range of epochs\n",
    "\n",
    "# Set up the matplotlib figure and axes, specifying the size and DPI for better resolution\n",
    "plt.figure(figsize=(10, 5), dpi=200)\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 1)  # 1 row, 2 columns, first subplot\n",
    "plt.plot(epochs, training_loss, 'navy', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'orangered', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(np.arange(1, len(epochs)+1, 1))  # Ensure ticks correspond to epochs\n",
    "plt.legend()\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.subplot(1, 2, 2)  # 1 row, 2 columns, second subplot\n",
    "plt.plot(epochs, training_acc, 'navy', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'orangered', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(np.arange(1, len(epochs)+1, 1))  # Ensure ticks correspond to epochs\n",
    "plt.legend()\n",
    "\n",
    "# Display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the model on unseen images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "sample_image_path = '/Users/riyanshibohra/Desktop/AI Project/safe_driving.jpeg'  # Replace with the actual path to your image\n",
    "image = load_img(sample_image_path, target_size=(240, 240))  # Adjust size if necessary\n",
    "image = img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)  # Model expects a batch\n",
    "\n",
    "# Preprocess the image as you did for your training data\n",
    "# Below is a simple rescaling example; adjust according to your preprocessing steps\n",
    "image = image / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(image)\n",
    "predicted_class = np.argmax(prediction, axis=1)[0]  # Get the numerical label\n",
    "print(f\"The image is classified as class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "sample_image_path2 = '/Users/riyanshibohra/Desktop/AI Project/test1.jpg'  # Replace with the actual path to your image\n",
    "image2 = load_img(sample_image_path2, target_size=(240, 240))  # Adjust size if necessary\n",
    "image2 = img_to_array(image2)\n",
    "image2 = np.expand_dims(image2, axis=0)  # Model expects a batch\n",
    "\n",
    "# Preprocess the image as you did for your training data\n",
    "# Below is a simple rescaling example; adjust according to your preprocessing steps\n",
    "image2 = image2 / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction2 = model.predict(image2)\n",
    "predicted_class2 = np.argmax(prediction2, axis=1)[0]  # Get the numerical label\n",
    "print(f\"The image is classified as class: {predicted_class2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(prediction2, axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Required - Face Forward\n"
     ]
    }
   ],
   "source": [
    "use_predicate_logic(prediction,start_location,end_location)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
